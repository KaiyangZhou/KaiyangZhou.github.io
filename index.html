<!DOCTYPE html>
<html>

<head>
    <title>Kaiyang Zhou's Home Page</title>

    <link rel="stylesheet" href="style.css">

    <meta charset="UTF-8">
    <meta name="description" content="Kaiyang Zhou's Home Page">
    <meta name="keywords" content="Kaiyang Zhou">
    <meta name="author" content="Kaiyang Zhou">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
</head>

<body>

<div id="contents">

<div class="profile-table">
  <img class="profile-img" src="images/ky-bu.jpg" width="180">
  <div class="profile-text">
    <h2> Kaiyang Zhou </h2>
    <p>
      <i>
        Assistant Professor <br>
        Department of Computer Science <br>
        Hong Kong Baptist University <br>
        Email: kyzhou [at] hkbu.edu.hk
      </i>
    </p>
    <p>
      <a href="pub.html">Publications</a> |
      <a href="https://scholar.google.com/citations?user=gRIejugAAAAJ">Google Scholar</a> |
      <a href="https://github.com/KaiyangZhou">Github</a> |
      <a href="https://twitter.com/kaiyangzhou">Twitter</a>
    </p>
  </div>
</div>

<hr noshade>

<p>
Dr. Kaiyang Zhou is an Assistant Professor at the <a href="https://www.comp.hkbu.edu.hk/">Department of Computer Science, Hong Kong Baptist University</a>, working on computer vision and machine learning. He has published over 30 technical papers in top-tier journals and conferences in relevant fields, with over 8,000 citations received in total. He currently serves as Associate Editor of the International Journal of Computer Vision and has served as area chair and senior program committee member for multiple top-tier conferences including NeurIPS, CVPR, ECCV, and AAAI. He is also the creator of several impactful AI software packages, such as <a href="https://github.com/KaiyangZhou/deep-person-reid">Torchreid</a> (the <a href="https://github.com/search?q=person+re-identification&type=repositories&s=stars&o=desc">No.1</a> popular person re-identification project on GitHub), <a href="https://github.com/KaiyangZhou/Dassl.pytorch">Dassl</a> (a multifunctional ML framework), and <a href="https://github.com/KaiyangZhou/CoOp">CoOp</a> (a prompt learning tool for improving vision-language models). Prior to joining HKBU, he was a postdoc at Nanyang Technological University, Singapore, working with Prof. <a href="https://liuziwei7.github.io/">Ziwei Liu</a> and Prof. <a href="https://www.mmlab-ntu.com/person/ccloy/">Chen Change Loy</a>. He received his PhD in computer science from the University of Surrey, UK, under the supervision of Prof. <a href="https://www.surrey.ac.uk/people/tao-xiang">Tao Xiang</a>.
</p>

<p>
Fields of specialization: multimodal models, domain generalization, domain adaptation.
</p>

<p>
<i>
To prospective students: I have multiple openings for PhD/RA with topics in LLM & VLM. If you are interested in joining my lab, please email me with your CV, transcripts, and other relevant material. You are highly recommended to contact me via email and receive my endorsement before submitting a formal PhD application to the Department. Due to the large volume of emails, I will only reply to shortlisted candidates.
</i>
</p>

<h3> News </h3>

<ul>
    <li> [2024-06] Invited to serve as AAAI 2025 senior program committee. </li>
    <li> [2024-06] We're organizing a workshop on <a href="https://prompting-in-vision.github.io/index_cvpr24.html">Prompting in Vision</a> at CVPR 2024. </li>
    <li> [2024-05] Invited to serve as BMVC 2024 area chair. </li>
    <li> [2024-04] <a href="https://green-fomo.github.io/ECCV2024/call.html">Call for Papers</a>: ECCV 2024 Workshop on Green Foundation Models. </li>
    <li> [2024-04] Invited to serve as NeurIPS 2024 area chair. </li>
    <li> [2024-02] <a href="https://prompting-in-vision.github.io/index_cvpr24.html">Call for Papers</a>: CVPR 2024 Workshop on Prompting in Vision. </li>
    <li> [2023-12] Invited to serve as ECCV 2024 area chair. </li>
    <li> [2023-10] Gave a talk at <a href="http://valser.org/article-697-1.html">VALSE</a>. </li>
    <li> [2023-08] Gave a talk at <a href="https://icaigc.org/workshops.html">AIGC-2023 Workshop on Trustworthy Foundation Models under Imperfect Data</a>. </li>
    <li> [2023-08] Gave a talk at <a href="https://www.cair-cas.org.hk/article/ijcai-medical-large-models">IJCAI-2023 Symposium Session on Medical Large Models</a>. </li>
    <li> [2023-08] Invited to serve as CVPR 2024 area chair. </li>
    <li> [2023-08] Invited to join the editorial board of International Journal of Computer Vision as associate editor. </li>
    <li> [2023-07] Gave a talk at the University of Tokyo (<a href="https://prompting-in-vision.github.io/slides/cvpr23/lecture-1a.pdf">slides</a> & <a href="https://youtu.be/fIoeCI3gH94">video</a>). </li>
    <li> [2023-06] We're organizing a tutorial on <a href="https://prompting-in-vision.github.io/">Prompting in Vision</a> at CVPR 2023. </li>
    <li> [2023-01] <a href="https://domaingen.github.io/">Call for Papers</a>: ICLR 2023 workshop on what do we need for successful domain generalization? </li>
    <li> [2022-09] <a href="assets/cfp_ijcv_lvms.html">Call for Papers</a>: IJCV Special Issue on The Promises and Dangers of Large Vision Models. </li>
</ul>

<h3> Professional services </h3>

<ul>
<li> Associate Editor: International Journal of Computer Vision (IJCV) </li>
<li> Guest Editor: IJCV Special Issue on <a href="assets/cfp_ijcv_lvms.html">The Promises and Dangers of Large Vision Models</a> </li>
<li> Area Chair / Senior Program Committee: NeurIPS, CVPR, ECCV, BMVC, AAAI </li>
<li> Organizing Committee: <a href="https://theaitalks.org">The AI Talks</a>, <a href="https://prompting-in-vision.github.io/">CVPR 2023 Prompting Tutorial</a>, <a href="https://domaingen.github.io/">ICLR 2023 DG Workshop</a>, <a href="https://prompting-in-vision.github.io/index_cvpr24.html">CVPR 2024 Prompting Workshop</a>, etc. </li>
<li> Reviewer: TPAMI, IJCV, ICLR, NeurIPS, ICML, AAAI, CVPR, ICCV, ECCV, etc. </li>
</ul>

<h3> Mentoring </h3>

<ul>
  <li> <a href="https://jiaerxia.github.io/">Jiaer Xia</a> (PhD, 2024-present) </li>
  <li> <a href="https://sifengshang.github.io/">Sifeng Shang</a> (PhD, 2024-present) </li>
  <li> <a href="https://tbbbk.github.io/">Bingkui Tong</a> (RA, 2024-present) </li>
</ul>

<h3> Teaching </h3>

<ul>
  <li>
    Hong Kong Baptist University <br>
    <i>COMP7065: Innovative Laboratory</i> <br>
    <i>ITS 7010: ITS Doctoral Research Training I</i>
  </li>
  <li>
    Nanyang Technological University <br>
    <i>AI6126 Guest Lecture: Open-World Visual Recognition</i> <br>
    <i>OpenMMLab Workshop: Object Detection</i>
  </li>
  <li>
    Queen Mary University of London <br>
    <i>ECS797: Machine Learning for Visual Data Analytics</i> <br>
    <i>ECS708: Machine Learning</i>
  </li>
</ul>

<h3> Software and datasets </h3>

<ul>
<li> <a href="https://github.com/KaiyangZhou/deep-person-reid">Torchreid</a>: A codebase for person re-identification (including <a href="https://kaiyangzhou.github.io/deep-person-reid/">documentation</a> and <a href="https://kaiyangzhou.github.io/deep-person-reid/MODEL_ZOO">model zoo</a>). </li>
<li> <a href="https://github.com/KaiyangZhou/Dassl.pytorch">Dassl</a>: A multifunctional codebase for domain generalization, domain adaptation and semi-supervised learning. </li>
<li> <a href="https://github.com/KaiyangZhou/CoOp">CoOp</a>: A codebase for developing adaptation methods (e.g., prompt learning) for large-scale vision-language models. </li>
<li> <a href="https://github.com/Jingkang50/OpenOOD">OpenOOD</a>: A codebase and benchmark for out-of-distribution detection. </li>
<li> <a href="http://psgdataset.org/">PSG</a>: A dataset for panoptic scene graph generation. (Codebase: <a href="https://github.com/Jingkang50/OpenPSG/">OpenPSG</a>.) </li>
</ul>

</div>

</body>
</html>
