<!DOCTYPE html>
<html>

<head>
    <title>Kaiyang Zhou's Home Page</title>

    <link rel="stylesheet" href="style.css">

    <meta charset="UTF-8">
    <meta name="description" content="Kaiyang Zhou's Home Page">
    <meta name="keywords" content="Kaiyang Zhou">
    <meta name="author" content="Kaiyang Zhou">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
</head>

<body>

<div id="contents">

<h2> Kaiyang Zhou </h2>
<img style="float:right" src="images/ky.png" width="150"></img>

<p>
Research Fellow (with <a href="https://www.mmlab-ntu.com/">MMLab@NTU</a>) <br>
School of Computer Science and Engineering <br>
Nanyang Technological University, Singapore <br><br>
Email: kaiyang.zhou at ntu.edu.sg <br><br>
Links:
<a href="pub.html">Publications</a> |
<a href="https://scholar.google.com/citations?user=gRIejugAAAAJ">Google Scholar</a> |
<a href="https://github.com/KaiyangZhou">Github</a> |
<a href="https://twitter.com/kaiyangzhou">Twitter</a>
</p>

<h3> Bio </h3>

<p>
Dr. Kaiyang Zhou is currently a research fellow at NTU Singapore, working with Prof. <a href="https://liuziwei7.github.io/">Ziwei Liu</a> and Prof. <a href="https://www.mmlab-ntu.com/person/ccloy/">Chen Change Loy</a>. He received his PhD in Computer Science from the University of Surrey, UK, under the supervision of Prof. <a href="http://personal.ee.surrey.ac.uk/Personal/T.Xiang/index.html">Tao Xiang</a>. His research interests lie at the intersection of machine learning and computer vision, with specialization in representation learning, domain generalization and data-efficient learning. He has published more than 20 papers at top-tier journals and conferences in relevant fields with over 3,000 citations received (h-index: 15). He is a guest editor of International Journal of Computer Vision (IJCV) and has served as an area chair and senior program committee member for BMVC 2022 and AAAI 2023, respectively. He is the creator of the popular open-source software <a href="https://github.com/KaiyangZhou/deep-person-reid">Torchreid</a> for person re-identification.
</p>

<h3> News </h3>

<ul>
<li> <a href="https://domaingen.github.io/">Call for Papers</a>: ICLR 2023 workshop on what do we need for successful domain generalization? (Deadline: <s>3 Feb 2023</s>) </li>
<li> <a href="assets/cfp_ijcv_lvms.html">Call for Papers</a>: IJCV Special Issue on The Promises and Dangers of Large Vision Models. (Deadline: <s>1 Apr 2023</s>) </li>
<li> Latest preprint: <a href="https://arxiv.org/pdf/2301.13670.pdf">What Makes Good Examples for Visual In-Context Learning?</a> </li>
<li> Latest preprint: <a href="https://arxiv.org/pdf/2210.07225.pdf">Unified Vision and Language Prompt Learning</a> </li>
<li> Latest preprint: <a href="https://arxiv.org/pdf/2206.04673">Neural Prompt Search</a> </li>
<li> Latest preprint: <a href="https://rdcu.be/c2Vtj">Semi-Supervised and Long-Tailed Object Detection with CascadeMatch</a> </li>
</ul>

<h3> Professional services </h3>

<ul>
    <li> <b>Guest Editor</b>: IJCV Special Issue on <a href="assets/cfp_ijcv_lvms.html">The Promises and Dangers of Large Vision Models</a> </li>
    <li> <b>Area Chair / Senior Program Committee</b>: BMVC 2022, AAAI 2023 </li>
    <li> <b>Organizer</b>: CVPR 2023 Tutorial on <a href="https://prompting-in-vision.github.io/">Prompting in Vision</a>, <a href="https://theaitalks.org">The AI Talks</a>, etc. </li>
    <li> <b>Reviewer</b>: TPAMI, IJCV, ICLR, NeurIPS, ICML, AAAI, CVPR, ICCV, ECCV, etc. </li>
</ul>

<h3> Software and datasets </h3>

<ul>
    <li> <a href="https://github.com/KaiyangZhou/deep-person-reid">Torchreid</a>: A codebase for person re-identification (with <a href="https://kaiyangzhou.github.io/deep-person-reid/">documentation</a> and <a href="https://kaiyangzhou.github.io/deep-person-reid/MODEL_ZOO">model zoo</a> provided). </li>
    <li> <a href="https://github.com/KaiyangZhou/Dassl.pytorch">Dassl</a>: A multifunctional codebase for domain generalization, domain adaptation and semi-supervised learning. </li>
    <li> <a href="https://github.com/KaiyangZhou/CoOp">CoOp</a>: A codebase for developing adaptation methods (e.g., prompt learning) for large-scale vision-language models. </li>
    <li> <a href="https://github.com/Jingkang50/OpenOOD">OpenOOD</a>: A codebase and benchmark for out-of-distribution detection. </li>
    <li> <a href="http://psgdataset.org/">PSG</a>: A dataset for panoptic scene graph generation. (Codebase: <a href="https://github.com/Jingkang50/OpenPSG/">OpenPSG</a>.) </li>
</ul>

</div>

</body>
</html>
