<!DOCTYPE html>
<html>

<head>
    <title>Call for Papers: IJCV Special Issue on The Promises and Dangers of Large Vision Models</title>

    <style>
        body {
            width: 98%;
            margin: 0 auto;
        }

        a:link {
            color: blue;
        }

        a:visited {
            color: blue;
        }

        a:hover {
            color: orange;
        }
    </style>

    <meta charset="UTF-8">
    <meta name="description" content="Call for Papers: IJCV Special Issue on The Promises and Dangers of Large Vision Models">
    <meta name="keywords" content="IJCV, Special Issue, Large Vision Models">
    <meta name="author" content="Kaiyang Zhou, Ziwei Liu, Xiaohua Zhai, Chunyuan Li, Kate Saenko">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
</head>

<body>

<br>
<img src="/images/research/ijcv_si_lvms.jpg" alt="Poster" width="800">

<h1>Call for Papers: IJCV Special Issue on <i>The Promises and Dangers of Large Vision Models</i></h1>

<h2>Guest Editors</h2>
<ul>
    <li><a href="https://kaiyangzhou.github.io/" target="_blank">Kaiyang Zhou</a>, Nanyang Technological University, Singapore</li>
    <li><a href="https://liuziwei7.github.io/" target="_blank">Ziwei Liu</a>, Nanyang Technological University, Singapore</li>
    <li><a href="https://sites.google.com/site/xzhai89" target="_blank">Xiaohua Zhai</a>, Google Brain, Switzerland</li>
    <li><a href="https://chunyuan.li/" target="_blank">Chunyuan Li</a>, Microsoft Research, Redmond, US</li>
    <li><a href="https://ai.bu.edu/ksaenko.html" target="_blank">Kate Saenko</a>, Boston University, US</li>
</ul>

<p>Computer vision, the science of teaching machines to understand the visual world, has witnessed in the past decade how the paradigm shift from hand-crafted methods to deep neural networks—known as deep learning—has revolutionized the field, leading to breakthroughs across a wide range of vision problems. Recently, we have observed a trend that has sparked new interests from the community and may greatly impact the field in the long run, i.e., the scaling of vision models.</p>

<p>Specifically, the size of vision models has grown exponentially from tens of millions of parameters to hundreds of millions, or even billions, particularly after the emergence of Vision Transformers. Moreover, the scale and diversity of training data also have been increased dramatically to match the growth in model capacity: not only in quantity (like billions of web examples) but also in modalities, such as combining image and language. Here we call them <i>Large Vision Models (LVMs)</i> for brevity, which include both unimodal and multimodal vision models (e.g., visual language models).</p>

<p>On one hand, LVMs learned from broad data at scale have demonstrated great power in terms of generalization capability: they can cope with a wide range of domains or scenarios, and can be adapted, with minimal twists, to handle multiple visual tasks, such as image classification/captioning/segmentation, object/keypoint detection, and depth/surface normal estimation. Furthermore, multimodal LVMs have also brought opportunities for numerous downstream zero-shot inference applications, such as open-vocabulary classification/detection/segmentation and image editing/generation.</p>

<p>On the other hand, LVMs come with challenges and risks that need to be addressed by the community: training is costly and has negative environmental impact; LVMs are too big to fine-tune on downstream datasets; uneven distribution of web data may cause social biases (w.r.t. gender and races) and inequalities; the commonsense reasoning ability of LVMs still lags behind; and so on.</p>

<p>This special issue seeks original contributions towards advancing LVMs—in terms of development, evaluation, adaptation, applications, understanding, and so on—and addressing the potential negative aspects brought by LVMs.</p>

<h2>Aims and Scope</h2>
Topics of interest include (but are not limited to):
<ul>
    <li>Training or adaptation methods for LVMs</li>
    <li>LVM architecture designs (not limited to Transformer-based models)</li>
    <li>Visualizing and interpreting LVMs</li>
    <li>Emergent capabilities of LVMs</li>
    <li>Applications and use cases of LVMs in computer vision</li>
    <li>Theoretical insights into LVMs</li>
    <li>Generalization and robustness of LVMs</li>
    <li>Evaluation, biases, fairness, and safety of LVMs</li>
</ul>

<h2>Important Dates</h2>
<ul>
    <li>Full paper submission deadline: March 1st, 2023</li>
    <li>Review deadline: April 30th, 2023</li>
    <li>Author response deadline: May 26th, 2023</li>
    <li>Final notification: June 26th, 2023</li>
    <li>Final manuscript submission: July 26th, 2023</li>
</ul>

<h2>Submission Guidelines</h2>

<p>Submitted papers should present original, unpublished work, relevant to one of the topics of the Special Issue. All submitted papers will be evaluated on the basis of relevance, significance of contribution, technical quality, scholarship, and quality of presentation, by at least three independent reviewers. It is the policy of the journal that no submission, or substantially overlapping submission, be published or be under review at another journal or conference at any time during the review process.</p>

<p>Please refer to the official <a href="https://www.springer.com/journal/11263/updates/23503548" target="_blank">CfP</a> on the International Journal of Computer Vision (IJCV) website for more information.</p>

</body>
</html>
