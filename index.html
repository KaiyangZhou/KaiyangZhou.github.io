<!DOCTYPE html>
<html>

<head>
    <title>Kaiyang Zhou's homepage</title>

    <link rel="stylesheet" href="style.css">

    <meta charset="UTF-8">
    <meta name="description" content="CVPR 2023 Tutorial on Prompting in Vision">
    <meta name="keywords" content="CVPR, Computer Vision, Prompting">
    <meta name="author" content="Kaiyang Zhou et al.">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
</head>

<body>

<div id="contents">

<h2> Kaiyang Zhou </h2>
<img style="float:right" src="images/ky.png" width="150"></img>

<p>
    Research Fellow, NTU Singapore (affiliated with <a href="https://www.mmlab-ntu.com/">MMLab@NTU</a>) <br>
    Email: kaiyang.zhou at ntu.edu.sg <br>
    Links:
    <a href="pub.html">Publications</a> |
    <a href="https://scholar.google.com/citations?user=gRIejugAAAAJ">Google Scholar</a> |
    <a href="https://github.com/KaiyangZhou">Github</a> |
    <a href="https://twitter.com/kaiyangzhou">Twitter</a>
</p>

<h3> Bio </h3>

<p> *<a href="assets/ZHOU_Kaiyang_CV.pdf">Download the full CV</a>. </p>

<p>
Dr. Kaiyang Zhou is currently a research fellow at NTU Singapore, working with Prof. <a href="https://liuziwei7.github.io/">Ziwei Liu</a> and Prof. <a href="https://www.mmlab-ntu.com/person/ccloy/">Chen Change Loy</a>. He received his PhD in Computer Science from the University of Surrey, UK, under the supervision of Prof. <a href="http://personal.ee.surrey.ac.uk/Personal/T.Xiang/index.html">Tao Xiang</a>. His research interests lie at the intersection of machine learning and computer vision. He has published more than 20 papers at top-tier journals and conferences in relevant fields with over 2,700 citations received in total (as of Feb 2023). He is a guest editor of the flagship journal in computer vision, International Journal of Computer Vision (IJCV), and has served as an area chair and senior program committee member for BMVC 2022 and AAAI 2023, respectively.
</p>

<h3> Research interests </h3>

<p>
Representation learning, foundation models, domain adaptation, domain generalization, semi-supervised learning, unsupervised learning, out-of-distribution detection, generative modeling, reinforcement learning, low-power design, and explainable AI.
</p>

<h3> News </h3>

<ul>
<li> <a href="https://domaingen.github.io/">Call for Papers</a>: ICLR 2023 workshop on what do we need for successful domain generalization? (Deadline: <s>3 Feb 2023</s>) </li>
<li> <a href="assets/cfp_ijcv_lvms.html">Call for Papers</a>: IJCV Special Issue on The Promises and Dangers of Large Vision Models. (Deadline: extended to 1 Apr 2023) </li>
</ul>

<h3> Latest papers </h3>

<ul>
<li> <a href="https://arxiv.org/pdf/2301.13670.pdf">What Makes Good Examples for Visual In-Context Learning?</a> </li>
<li> <a href="https://arxiv.org/pdf/2210.07225.pdf">Unified Vision and Language Prompt Learning</a> </li>
<li> <a href="https://arxiv.org/pdf/2206.04673">Neural Prompt Search</a> </li>
<li> <a href="https://rdcu.be/c2Vtj">Semi-Supervised and Long-Tailed Object Detection with CascadeMatch</a> </li>
</ul>

<h3> Selected publications </h3>

<p> *<a href="pub.html">Full list</a>. </p>

<ul>
<li> K. Zhou, Z. Liu, Y. Qiao, T. Xiang, and C. C. Loy, "<a href="https://arxiv.org/abs/2103.02503">Domain Generalization: A Survey</a>," TPAMI, 2022. </li>
<li> K. Zhou, J. Yang, C. C. Loy, and Z. Liu, "<a href="https://arxiv.org/abs/2203.05557">Conditional Prompt Learning for Vision-Language Models</a>," in CVPR, 2022. </li>
<li> K. Zhou, J. Yang, C. C. Loy, and Z. Liu, "<a href="https://arxiv.org/abs/2109.01134">Learning to Prompt for Vision-Language Models</a>," IJCV, 2022. </li>
<li> K. Zhou, Y. Yang, Y. Qiao, and T. Xiang, "<a href="https://arxiv.org/abs/2003.07325">Domain Adaptive Ensemble Learning</a>," TIP, 2021. </li>
<li> K. Zhou, Y. Yang, A. Cavallaro, and T. Xiang, "<a href="https://arxiv.org/abs/1910.06827">Learning Generalisable Omni-Scale Representations for Person Re-Identification</a>," TPAMI, 2021. </li>
<li> K. Zhou, Y. Yang, Y. Qiao, and T. Xiang, "<a href="https://arxiv.org/abs/2104.02008">Domain Generalization with MixStyle</a>," in ICLR, 2021. </li>
<li> K. Zhou, Y. Yang, T. Hospedales, and T. Xiang, "<a href="https://arxiv.org/abs/2007.03304">Learning to Generate Novel Domains for Domain Generalization</a>," in ECCV, 2020. </li>
<li> K. Zhou, Y. Yang, T. Hospedales, and T. Xiang, "<a href="https://arxiv.org/abs/2003.06054">Deep Domain-Adversarial Image Generation for Domain Generalisation</a>," in AAAI, 2020. </li>
<li> K. Zhou, Y. Yang, A. Cavallaro, and T. Xiang, "<a href="https://arxiv.org/abs/1905.00953">Omni-Scale Feature Learning for Person Re-Identification</a>," in ICCV, 2019. </li>
<li> K. Zhou, Y. Qiao, and T. Xiang, "<a href="https://arxiv.org/abs/1801.00054">Deep Reinforcement Learning for Unsupervised Video Summarization with Diversity-Representativeness Reward</a>," in AAAI, 2018. </li>
</ul>

<h3> Professional services </h3>

<ul>
    <li> <b>Guest Editor</b>: IJCV Special Issue on <a href="assets/cfp_ijcv_lvms.html">The Promises and Dangers of Large Vision Models</a> </li>
    <li> <b>Area Chair / Senior Program Committee</b>: BMVC 2022, AAAI 2023 </li>
    <li> <b>Organizer</b>: CVPR 2023 Tutorial on <a href="https://prompting-in-vision.github.io/">Prompting in Vision</a>, <a href="https://theaitalks.org">The AI Talks</a>, etc. </li>
    <li> <b>Reviewer</b>: TPAMI, IJCV, ICLR, NeurIPS, ICML, AAAI, CVPR, ICCV, ECCV, etc. </li>
</ul>

</div>

</body>
</html>
