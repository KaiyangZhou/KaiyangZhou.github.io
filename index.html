<!DOCTYPE html>
<html>

<head>
    <title>Kaiyang Zhou's Home Page</title>

    <link rel="stylesheet" href="style.css">

    <meta charset="UTF-8">
    <meta name="description" content="CVPR 2023 Tutorial on Prompting in Vision">
    <meta name="keywords" content="CVPR, Computer Vision, Prompting">
    <meta name="author" content="Kaiyang Zhou et al.">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
</head>

<body>

<div id="contents">

<h2> Kaiyang Zhou </h2>
<img style="float:right" src="images/ky.png" width="150"></img>

<p>
Research Fellow, NTU Singapore (affiliated with <a href="https://www.mmlab-ntu.com/">MMLab@NTU</a>) <br>
Email: kaiyang.zhou at ntu.edu.sg <br>
Links:
<a href="pub.html">Publications</a> |
<a href="https://scholar.google.com/citations?user=gRIejugAAAAJ">Google Scholar</a> |
<a href="https://github.com/KaiyangZhou">Github</a> |
<a href="https://twitter.com/kaiyangzhou">Twitter</a>
</p>
<br>

<h3> Bio </h3>

<p>
Dr. Kaiyang Zhou is currently a research fellow at NTU Singapore, working with Prof. <a href="https://liuziwei7.github.io/">Ziwei Liu</a> and Prof. <a href="https://www.mmlab-ntu.com/person/ccloy/">Chen Change Loy</a>. He received his PhD in Computer Science from the University of Surrey, UK, under the supervision of Prof. <a href="http://personal.ee.surrey.ac.uk/Personal/T.Xiang/index.html">Tao Xiang</a>. His research interests lie at the intersection of machine learning and computer vision. He has published more than 20 papers at top-tier journals and conferences in relevant fields with over 2,700 citations (h-index: 15) received in total (as of Feb 2023). He is a guest editor of the flagship journal in computer vision, International Journal of Computer Vision (IJCV), and has served as an area chair and senior program committee member for BMVC 2022 and AAAI 2023, respectively.
<a href="assets/ZHOU_Kaiyang_CV.pdf">Download the full CV</a>
</p>

<h3> Research interests </h3>

<p>
Representation learning, foundation models, domain adaptation, domain generalization, semi-supervised learning, unsupervised learning, out-of-distribution detection, generative modeling, reinforcement learning, low-power design, and explainable AI.
</p>

<h3> News </h3>

<ul>
<li> <a href="https://domaingen.github.io/">Call for Papers</a>: ICLR 2023 workshop on what do we need for successful domain generalization? (Deadline: <s>3 Feb 2023</s>) </li>
<li> <a href="assets/cfp_ijcv_lvms.html">Call for Papers</a>: IJCV Special Issue on The Promises and Dangers of Large Vision Models. (Deadline: extended to 1 Apr 2023) </li>
<li> (Latest paper) <a href="https://arxiv.org/pdf/2301.13670.pdf">What Makes Good Examples for Visual In-Context Learning?</a> </li>
<li> (Latest paper) <a href="https://arxiv.org/pdf/2210.07225.pdf">Unified Vision and Language Prompt Learning</a> </li>
<li> (Latest paper) <a href="https://arxiv.org/pdf/2206.04673">Neural Prompt Search</a> </li>
<li> (Latest paper) <a href="https://rdcu.be/c2Vtj">Semi-Supervised and Long-Tailed Object Detection with CascadeMatch</a> </li>
</ul>

<h3> Professional services </h3>

<ul>
    <li> <b>Guest Editor</b>: IJCV Special Issue on <a href="assets/cfp_ijcv_lvms.html">The Promises and Dangers of Large Vision Models</a> </li>
    <li> <b>Area Chair / Senior Program Committee</b>: BMVC 2022, AAAI 2023 </li>
    <li> <b>Organizer</b>: CVPR 2023 Tutorial on <a href="https://prompting-in-vision.github.io/">Prompting in Vision</a>, <a href="https://theaitalks.org">The AI Talks</a>, etc. </li>
    <li> <b>Reviewer</b>: TPAMI, IJCV, ICLR, NeurIPS, ICML, AAAI, CVPR, ICCV, ECCV, etc. </li>
</ul>

</div>

</body>
</html>
